from fastapi import FastAPI,HTTPException,Request
from pydantic import BaseModel
from fastapi.middleware.cors import CORSMiddleware
from datetime import datetime, timedelta
import os
import json
import subprocess
from typing import Optional
import logging
from dateutil import parser
import mysql.connector
import pymysql
from collections import defaultdict
# from openai import OpenAI
from openai import AzureOpenAI
import httpx
from pathlib import Path
import sys
from urllib.parse import unquote
from dotenv import load_dotenv
import traceback
from fastapi.responses import JSONResponse

# ãƒ­ãƒ¼ã‚«ãƒ«ç”¨ .env èª­ã¿è¾¼ã¿ï¼ˆAzureç’°å¢ƒã§ã¯ç„¡è¦–ã•ã‚Œã‚‹ï¼‰
load_dotenv()

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[logging.StreamHandler(sys.stdout)]
)

logger = logging.getLogger(__name__)

# api_key = os.getenv("OPENAI_API_KEY")
# if not api_key:
#     raise RuntimeError("âŒ OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚Azure ã®æ§‹æˆã¾ãŸã¯ .env ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

# client = OpenAI(api_key=api_key)

client = AzureOpenAI(
    api_key=os.getenv("OPENAI_API_KEY"),
    api_version=os.getenv("OPENAI_API_VERSION"),
    azure_endpoint=os.getenv("OPENAI_API_BASE")
)

app = FastAPI()

# CORSè¨­å®šï¼ˆNext.jsã¨ã®é€£æºã®ãŸã‚ï¼‰
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# MySQLæ¥ç¶šæƒ…å ±
DB_CONFIG = {
    "host": os.getenv("MYSQL_HOST", "tech0-gen-8-step4-dtx-db.mysql.database.azure.com"),
    "user": os.getenv("MYSQL_USER", "ryoueno"),
    "password": os.getenv("MYSQL_PASSWORD", "tech0-dtxdb"),
    "database": "corporaiters"
}


def get_db_connection():
    return mysql.connector.connect(**DB_CONFIG)

# å•†å“ãƒã‚¹ã‚¿å–å¾—API
TABLE_NAME = "shipping_company"

#ãƒ†ã‚¹ãƒˆç”¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.get("/test-env")
def test_env():
    openai_key = os.getenv("OPENAI_API_KEY")
    if openai_key:
        return {"status": "success", "openai_key_snippet": openai_key[:5] + "..." + openai_key[-5:]}
    else:
        return {"status": "failure", "error": "OPENAI_API_KEY not found"}

@app.get("/")
async def root():
    return {"message": "Hello, FastAPI!"}

# ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£å®šç¾©
class ShippingRequest(BaseModel):
    departure_port: str
    destination_port: str
    etd_date: Optional[str] = None
    eta_date: Optional[str] = None

class ScheduleRequest(BaseModel):
    departure_port: str
    destination_port: str
    etd_date: Optional[str]
    eta_date: Optional[str]

class FeedbackRequest(BaseModel):
    url: str
    etd: str
    eta: str
    feedback: str

async def extract_schedule_positions(
    url: str,
    departure: str,
    destination: str,
    etd_date: datetime = None,
    eta_date: datetime = None
):
    import os
    import csv
    import json
    import re
    import requests
    import fitz  # PyMuPDF
    from datetime import datetime
    # from openai import OpenAI

    DESTINATION_ALIASES = {
        "New York": ["NEW YORK", "NYC", "NEWYORK", "N.Y.", "NY"],
        "Los Angeles": ["LOS ANGELES", "LA", "L.A."],
        "Rotterdam": ["ROTTERDAM"],
        "Hamburg": ["HAMBURG"],
        "Norfolk": ["NORFOLK", "ORF"],
        "Savannah": ["SAVANNAH", "SAV"],
        "Charleston": ["CHARLESTON"],
        "Miami": ["MIAMI", "MIA"],
        "Oakland": ["OAKLAND", "OAK"],
        "Houston": ["HOUSTON", "HOU"],
        "Dallas": ["DALLAS", "FWO", "FORT WORTH", "FT WORTH"],
        "Memphis": ["MEMPHIS", "MEM"],
        "Atlanta": ["ATLANTA", "ATL"],
        "Chicago": ["CHICAGO", "CHI"],
        "Columbus": ["COLUMBUS", "CMH"],
        "Singapore": ["SINGAPORE", "SGP"],
        "Jakarta": ["JAKARTA"],
        "Port Klang": ["PORT KLANG", "PORT KLANG (W)", "PORT KLANG (N)", "PKG", "PKW"],
        "Penang": ["PENANG"],
        "Surabaya": ["SURABAYA"],
        "Bangkok": ["BANGKOK"],
        "Ho Chi Minh": ["HO CHI MINH", "HCM", "SAIGON"],
        "Haiphong": ["HAIPHONG", "HPH"],
        "Hanoi": ["HANOI"],
        "Manila": ["MANILA", "MNL"],
        "Busan": ["BUSAN", "PUSAN", "PUS"],
        "Hong Kong": ["HONG KONG", "HK", "HKG"],
        "Kaohsiung": ["KAOHSIUNG", "KHH"],
        "Sydney": ["SYDNEY", "SYD"],
        "Melbourne": ["MELBOURNE", "MEL"],
        "Adelaide": ["ADELAIDE", "ADL"],
        "Fremantle": ["FREMANTLE", "FRE"],
        "Brisbane": ["BRISBANE", "BNE"],
        "Xiamen": ["XIAMEN"],
        "Qingdao": ["QINGDAO", "TSINGTAO"],
        "Dalian": ["DALIAN"],
        "Shanghai": ["SHANGHAI"],
        "Ningbo": ["NINGBO"],
        "Shekou": ["SHEKOU"],
        "Yantian": ["YANTIAN", "YTN"],
        "Nansha": ["NANSHA"],
        "Shenzhen": ["SHENZHEN"],
        "Tanjung Pelepas": ["TANJUNG PELEPAS", "TPP"],
        "Port Kelang": ["PORT KELANG", "PORTKLANG"],  # é€šç§°é•ã„å¯¾å¿œ
    }

    if not etd_date and not eta_date:
        return {"error": "ETDã‹ETAã®ã„ãšã‚Œã‹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚"}

    base_date = etd_date or eta_date

    # PDFã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    logger.info(f"ğŸ“¥ PDFãƒªãƒ³ã‚¯ã«ã‚¢ã‚¯ã‚»ã‚¹ä¸­: {url}")
    response = requests.get(url)
    
    if response.status_code != 200:
        logger.error(f"âŒ PDFã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰: {response.status_code}")
        return None

    logger.info("ğŸ“ temp_schedule.pdf ã‚’ä¿å­˜ä¸­...")
    with open("temp_schedule.pdf", "wb") as f:
        f.write(response.content)
    logger.info("ğŸ“„ PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’temp_schedule.pdfã¨ã—ã¦ä¿å­˜ã—ã¾ã—ãŸã€‚")

    doc = None
    try:
        logger.info("ğŸ” PDFã‚’é–‹ã„ã¦ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã‚’é–‹å§‹ã—ã¾ã™ã€‚")
        doc = fitz.open("temp_schedule.pdf")
        full_text = "\n".join(page.get_text("text") for page in doc)
        logger.info(f"âœ… PDFã‹ã‚‰ã®ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºå®Œäº†ã€‚")

        # ã‚¨ã‚¤ãƒªã‚¢ã‚¹ç”Ÿæˆï¼ˆå¤§æ–‡å­—åŒ–ã—ã¦æ­£è¦åŒ–ï¼‰
        aliases = DESTINATION_ALIASES.get(destination, [destination])
        aliases = [a.upper() for a in aliases]

        # å€™è£œè¡Œã®ã¿æŠ½å‡ºï¼ˆæ—¥ä»˜ + ç›®çš„åœ°ã‚¨ã‚¤ãƒªã‚¢ã‚¹ã‚’å«ã‚€è¡Œï¼‰
        lines = full_text.splitlines()

        # è¡Œã®ç¢ºèª
        logger.info("ğŸ” å„è¡Œã®è©³ç´°ã‚’è¡¨ç¤ºã—ã¾ã™ï¼š")
        for idx, line in enumerate(lines):
            logger.info(f"è¡Œ {idx + 1}: {repr(line)}")

        candidate_lines = set()
        for i in range(len(lines)):
            line_upper = lines[i].upper()
            if re.search(r'\d{1,2}/\d{1,2}', line_upper) and any(alias in line_upper for alias in aliases):
                block = lines[max(0, i - 2):min(len(lines), i + 3)]
                candidate_lines.update(block)

        # ãƒˆãƒ¼ã‚¯ãƒ³å‰Šæ¸›ã®ãŸã‚ã€æ–‡å­—æ•°åˆ¶é™ï¼ˆä¾‹: 4096æ–‡å­—ï¼‰
        condensed_text = "\n".join(candidate_lines)
        if len(condensed_text) > 4096:
            condensed_text = condensed_text[:4096]  # GPT-4oã®ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã«å¯¾å¿œ
        
        # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã« condensed_text ã‚’å‡ºåŠ›
        logger.info(f"âœ… Condensed Text:\n{condensed_text}")

        prompt = f"""
ä»¥ä¸‹ã¯PDFã‹ã‚‰æŠ½å‡ºã•ã‚ŒãŸã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å€™è£œã®è¡Œã§ã™ã€‚
ç›®çš„åœ°ã€Œ{destination}ã€ï¼ˆåˆ¥å: {', '.join(aliases)}ï¼‰ã«é–¢é€£ã™ã‚‹ã€
æœ€ã‚‚{base_date.strftime('%m/%d')}ã«è¿‘ã„ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆèˆ¹åãƒ»ETDãƒ»ETAï¼‰ã‚’1ä»¶ã ã‘æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

å‡ºç™ºåœ°ã¾ãŸã¯ç›®çš„åœ°ãŒæ˜ç¢ºã«åˆ†ã‹ã‚‹å ´åˆã¯ã€è©²å½“ã™ã‚‹æ—¥ä»˜ï¼ˆETD/ETAï¼‰ã‚‚å¿…ãšæŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

å‡ºåŠ›å½¢å¼ï¼ˆå¿…ãšJSONå½¢å¼ï¼‰:
{{
  "vessel": "èˆ¹å",
  "etd": "MM/DD ã¾ãŸã¯ MM/DD - MM/DD",
  "eta": "MM/DD"
}}
---
{full_text}
"""

        # client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

        chat_response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯è²¿æ˜“å®Ÿå‹™ã«è©³ã—ã„ç†Ÿç·´ã®èˆ¹ä¾¿é¸å®šã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã§ã™ã€‚"},
                {"role": "user", "content": prompt},
            ]
        )

        reply_text = chat_response.choices[0].message.content

        match = re.search(r'\{[\s\S]*?\}', reply_text)
        if not match:
            logger.warning("[WARNING] ChatGPTã®è¿”ç­”ãŒJSONå½¢å¼ã§ãªã„ãŸã‚è§£æä¸å¯")
            return {
                "error": "ChatGPTã®è¿”ç­”ãŒJSONå½¢å¼ã§å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“", 
                "raw_response": reply_text,
                "vessel": "",
                "etd": "",
                "eta": "",
                "fare": "",
                "schedule_url": url
                }

        try:
            info = json.loads(match.group())
            etd_date_str = info.get("etd")
            eta_date_str = info.get("eta")
            vessel = info.get("vessel")

            log_path = "gpt_feedback_log.csv"
            new_entry = [
                datetime.now().isoformat(),
                url,
                departure,
                destination,
                base_date.strftime("%Y-%m-%d"),
                etd_date_str,
                eta_date_str,
                vessel,
                "pending"
            ]

            file_exists = os.path.exists(log_path)
            with open(log_path, "a", newline='', encoding='utf-8') as log_file:
                writer = csv.writer(log_file)
                if not file_exists:
                    writer.writerow(["timestamp", "url", "departure", "destination", "input_date", "etd", "eta", "vessel", "feedback"])
                writer.writerow(new_entry)

            return {
                "company": "ONE",
                "fare": "$",
                "etd": etd_date_str,
                "eta": eta_date_str,
                "vessel": vessel,
                "schedule_url": url,
                "raw_response": reply_text
            }
        except Exception as e:
            return {"error": "ChatGPTã®è¿”ç­”ãŒãƒ‘ãƒ¼ã‚¹ã§ãã¾ã›ã‚“ã§ã—ãŸ", "raw_response": reply_text}

    except Exception as e:
        # import logging
        # logger = logging.getLogger(__name__)
        logger.error(f"PyMuPDFè§£æå¤±æ•—: {e}")
        return None

    finally:
        try:
            if doc:
                doc.close()
        except:
            pass
        try:
            os.remove("temp_schedule.pdf")
            logger.info("ğŸ§¹ ä¸€æ™‚PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")
        except Exception as e:
            # import logging
            # logger = logging.getLogger(__name__)
            logger.warning(f"[WARN] PDFå‰Šé™¤ã«å¤±æ•—: {e}")


async def get_pdf_links_from_one(destination_keyword: str) -> list[str]:
    try:
        # app/get_pdf_links.py ã®ãƒ‘ã‚¹ã‚’æŒ‡å®š
        script_path = Path(__file__).resolve().parent / "app" / "get_pdf_links.py"
        cwd_path = script_path.parent

        result = subprocess.run(
            [sys.executable, str(script_path), destination_keyword, "--silent"],
            capture_output=True,
            text=True,
            check=True,
            cwd=str(cwd_path),
            env=os.environ.copy(),
        )

        logger.info(f"[DEBUG] get_pdf_links.py stdout:\n{result.stdout}")
        return json.loads(result.stdout)
    
    except json.JSONDecodeError as je:
        logger.error(f"[ERROR] JSON Decode Error: {je}")
        logger.error(f"[DEBUG] å®Ÿéš›ã®å‡ºåŠ›å†…å®¹: {result.stdout}")
        return []
    
    except subprocess.CalledProcessError as cpe:
        logger.error(f"[CalledProcessError] stderr:\n{cpe.stderr}")
        logger.error(f"[CalledProcessError] stdout:\n{cpe.stdout}")
        return []
    
    except Exception as e:
        logger.error(f"[ERROR] ONE get_pdf_links å®Ÿè¡Œå¤±æ•—: {e}")
        return []
    
# COSCOã®PDFãƒªãƒ³ã‚¯å–å¾—ç”¨
async def get_pdf_links_from_cosco(destination_keyword: str) -> list[str]:
    try:
        # get_cosco_pdf_links.py ã®ãƒ•ãƒ«ãƒ‘ã‚¹ã‚’æŒ‡å®š
        script_path = Path(__file__).resolve().parent / "app" / "get_cosco_pdf_links.py"
        cwd_path = script_path.parent

        result = subprocess.run(
            [sys.executable, str(script_path), destination_keyword, "--silent"],
            capture_output=True,
            text=True,
            check=True,
            cwd=str(cwd_path),  # .envãŒèª­ã‚ã‚‹ã‚ˆã†ã«
            env=os.environ.copy(),  # ç¾åœ¨ã®ç’°å¢ƒå¤‰æ•°ã‚’æ˜ç¤ºçš„ã«æ¸¡ã™ï¼ˆPlaywrightã®å®Ÿè¡Œã«ã‚‚å¿…è¦ï¼‰
        )

        logger.info(f"[COSCO PDFãƒªãƒ³ã‚¯å–å¾—] stdout:\n{result.stdout}")
        return json.loads(result.stdout)

    except json.JSONDecodeError as je:
        logger.error(f"[ERROR] JSON Decode Error: {je}")
        logger.error(f"[DEBUG] å®Ÿéš›ã®å‡ºåŠ›å†…å®¹: {result.stdout}")
        return []

    except subprocess.CalledProcessError as spe:
        logger.error(f"[ERROR] CalledProcessError: {spe}")
        logger.error(f"[stderr]\n{spe.stderr}")
        return []

    except Exception as e:
        logger.error(f"[ERROR] COSCO get_pdf_links å®Ÿè¡Œå¤±æ•—: {e}")
        return []
    
# KINKAã®PDFãƒªãƒ³ã‚¯å–å¾—ç”¨
async def get_pdf_links_from_kinka(destination_keyword: str) -> list[str]:
    try:
        script_path = Path(__file__).resolve().parent / "app" / "get_kinka_pdf_links.py"
        cwd_path = script_path.parent

        result = subprocess.run(
            [sys.executable, str(script_path), destination_keyword, "--silent"],
            capture_output=True,
            text=True,
            check=True,
            cwd=str(cwd_path),  # .envãŒèª­ã‚ã‚‹ã‚ˆã†ã«
            env=os.environ.copy(),  # ç¾åœ¨ã®ç’°å¢ƒå¤‰æ•°ã‚’æ˜ç¤ºçš„ã«æ¸¡ã™ï¼ˆPlaywrightã®å®Ÿè¡Œã«ã‚‚å¿…è¦ï¼‰
        )

        logger.info(f"[KINKA PDFãƒªãƒ³ã‚¯å–å¾—] stdout:\n{result.stdout}")
        return json.loads(result.stdout)
    except json.JSONDecodeError as je:
        logger.error(f"[ERROR] JSON Decode Error: {je}")
        logger.error(f"[DEBUG] å®Ÿéš›ã®å‡ºåŠ›å†…å®¹: {result.stdout}")
        return []
    except Exception as e:
        logger.error(f"[ERROR] KINKA get_pdf_links å®Ÿè¡Œå¤±æ•—: {e}")
        return []

# Shipmentlinkã®PDFãƒªãƒ³ã‚¯å–å¾—ç”¨
async def get_pdf_links_from_shipmentlink(departure_port: str, destination_port: str) -> list[str]:
    try:
        script_path = Path(__file__).resolve().parent / "app" / "get_shipmentlink_pdf_links.py"
        cwd_path = script_path.parent

        result = subprocess.run(
            [sys.executable, str(script_path), departure_port, destination_port, "--silent"],
            capture_output=True,
            text=True,
            check=True,
            cwd=str(cwd_path),  # .envãŒèª­ã‚ã‚‹ã‚ˆã†ã«
            env=os.environ.copy(),  # ç¾åœ¨ã®ç’°å¢ƒå¤‰æ•°ã‚’æ˜ç¤ºçš„ã«æ¸¡ã™ï¼ˆPlaywrightã®å®Ÿè¡Œã«ã‚‚å¿…è¦ï¼‰
        )

        logger.info(f"[Shipmentlink PDFå–å¾—] raw stdout:\n{result.stdout}")
        # JSONãƒ‡ã‚³ãƒ¼ãƒ‰å¾Œã€URLãƒ‡ã‚³ãƒ¼ãƒ‰
        raw_links = json.loads(result.stdout)
        decoded_links = [unquote(url) for url in raw_links]  # âœ… ã“ã“ã§ä¸€æ‹¬å¤‰æ›
        logger.info(f"[Shipmentlink PDFå–å¾—] decoded:\n{decoded_links}")  # âœ… ãƒ­ã‚°ã«å¿…ãšå‡ºåŠ›ï¼
        
        return decoded_links
    except Exception as e:
        logger.error(f"[Shipmentlinkå–å¾—å¤±æ•—] {e}")
        return []

# FastAPI å†…ã®éåŒæœŸé–¢æ•°
async def get_schedule_from_maersk(departure: str, destination: str, etd_date: str) -> list[dict]:
    try:
        api_key = os.getenv("MAERSK_API_KEY")  # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—
        if not api_key:
            raise Exception("MAERSK_API_KEY ãŒæœªè¨­å®šã§ã™")

        # UN/LOCODEå¯¾å¿œï¼ˆä¾‹: Tokyo -> JP, Los Angeles -> USï¼‰
        ORIGIN_CODE_MAP = {
            "Tokyo": ("JP", "Tokyo"),
            "Shanghai": ("CN", "Shanghai")
        }
        DEST_CODE_MAP = {
            "Los Angeles": ("US", "Los Angeles"),
            "Long Beach": ("US", "Long Beach")
        }

        origin_country, origin_city = ORIGIN_CODE_MAP.get(departure, (None, None))
        dest_country, dest_city = DEST_CODE_MAP.get(destination, (None, None))

        if not origin_country or not dest_country:
            raise Exception(f"éƒ½å¸‚ã‚³ãƒ¼ãƒ‰æœªå¯¾å¿œ: {departure} / {destination}")

        # APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        url = "https://api.maersk.com/products/ocean-products"
        params = {
            "vesselOperatorCarrierCode": "MAEU",
            "collectionOriginCountryCode": origin_country,
            "collectionOriginCityName": origin_city,
            "deliveryDestinationCountryCode": dest_country,
            "deliveryDestinationCityName": dest_city,
        }

        headers = {
            "Consumer-Key": api_key,
            "Accept": "application/json"
        }

        async with httpx.AsyncClient() as client:
            response = await client.get(url, headers=headers, params=params, timeout=30.0)

        if response.status_code == 200:
            data = response.json()

            # å¿…è¦ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ã¿æŠ½å‡ºã—ã¦æ•´å½¢
            # â€»ä¸‹è¨˜ã¯ã‚µãƒ³ãƒ—ãƒ«æ§‹æˆã§ã€å®Ÿéš›ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«åˆã‚ã›ã¦èª¿æ•´å¿…è¦
            results = []
            for item in data.get("schedules", []):
                results.append({
                    "vessel": item.get("vesselName"),
                    "etd": item.get("departureDate"),
                    "eta": item.get("arrivalDate"),
                    "service": item.get("serviceName"),
                })

            return results
        else:
            logger.warning(f"Maersk APIã‚¨ãƒ©ãƒ¼: {response.status_code} - {response.text}")
            return []

    except Exception as e:
        logger.error(f"[Maersk APIå–å¾—ä¾‹å¤–] {str(e)}")
        return []

# Hapag-Lloydã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å–å¾—é–¢æ•°ã‚’è¿½åŠ 
# async def get_schedule_from_hapaglloyd(departure: str, destination: str) -> list[dict]:
#     from playwright.async_api import async_playwright
#     results = []
#     try:
#         async with async_playwright() as p:
#             browser = await p.chromium.launch(headless=True)
#             page = await browser.new_page()
#             await page.goto("https://www.hapag-lloyd.com/solutions/schedule/#/", timeout=60000)
#             await page.wait_for_load_state("networkidle")

#             from_input = await page.wait_for_selector('input[aria-label="From"]', timeout=10000)
#             await from_input.fill(departure)
#             await page.wait_for_timeout(500)
#             await page.keyboard.press("ArrowDown")
#             await page.keyboard.press("Enter")

#             to_input = await page.wait_for_selector('input[aria-label="To"]', timeout=10000)
#             await to_input.fill(destination)
#             await page.wait_for_timeout(500)
#             await page.keyboard.press("ArrowDown")
#             await page.keyboard.press("Enter")

#             await page.click('button:has-text("Search")')

#             await page.wait_for_selector('.schedule-table-container', timeout=20000)
#             rows = await page.query_selector_all('.schedule-table-container tbody tr')

#             for row in rows[:3]:
#                 cols = await row.query_selector_all('td')
#                 if len(cols) >= 5:
#                     vessel = await cols[0].inner_text()
#                     etd = await cols[2].inner_text()
#                     eta = await cols[3].inner_text()
#                     results.append({
#                         "company": "Hapag-Lloyd",
#                         "vessel": vessel.strip(),
#                         "etd": etd.strip(),
#                         "eta": eta.strip(),
#                         "fare": "",
#                         "schedule_url": page.url,
#                         "raw_response": f"{vessel.strip()} {etd.strip()}->{eta.strip()}"
#                     })
#             await browser.close()
#     except Exception as e:
#         logger.error(f"[Hapag-Lloyd ERROR] {e}")
#     return results

@app.post("/recommend-shipping")
async def recommend_shipping(req: ShippingRequest):
    logger.info("ğŸ“¦ ãƒªã‚¯ã‚¨ã‚¹ãƒˆå—ä¿¡:")
    logger.info(f"  Departure Port: {req.departure_port}")
    logger.info(f"  Destination Port: {req.destination_port}")
    logger.info(f"  ETD: {req.etd_date}")
    logger.info(f"  ETA: {req.eta_date}")

    if not req.etd_date and not req.eta_date:
        return {"error": "ETDã‹ETAã®ã„ãšã‚Œã‹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚"}

    destination = req.destination_port
    departure = req.departure_port
    keyword = destination
    etd_date = datetime.strptime(req.etd_date, "%Y-%m-%d") if req.etd_date else None
    eta_date = datetime.strptime(req.eta_date, "%Y-%m-%d") if req.eta_date else None
 

    results = []

    # ========== ONEç¤¾ ==========
    logger.info(f"ğŸ” ONEç¤¾ get_pdf_links.py ã«æ¸¡ã™ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: '{keyword}'")
    pdf_urls_one = await get_pdf_links_from_one(keyword)
    if not pdf_urls_one:
        logger.warning("âš ï¸ ONEç¤¾ã®PDFãƒªãƒ³ã‚¯å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
    else:
        for pdf_url in pdf_urls_one:
            result = await extract_schedule_positions(
                url=pdf_url,
                departure=departure,
                destination=destination,
                etd_date=etd_date,
                eta_date=eta_date
            )
            if result:
                result["company"] = "ONE"
                results.append(result)
                logger.info(f"[ONEç¤¾ãƒãƒƒãƒ] {result}")
                break  # æœ€åˆã®ãƒãƒƒãƒã§æ­¢ã‚ã‚‹

    # ========== COSCOç¤¾ ==========
    logger.info(f"ğŸ” COSCOç¤¾ get_cosco_pdf_links.py ã«æ¸¡ã™ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: '{keyword}'")
    pdf_urls_cosco = await get_pdf_links_from_cosco(keyword)
    if not pdf_urls_cosco:
        logger.warning("âš ï¸ COSCOç¤¾ã®PDFãƒªãƒ³ã‚¯å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
    else:
        for pdf_url in pdf_urls_cosco:
            result = await extract_schedule_positions(
                url=pdf_url,
                departure=departure,
                destination=destination,
                etd_date=etd_date,
                eta_date=eta_date
            )
            if result:
                result["company"] = "COSCO"
                results.append(result)
                logger.info(f"[COSCOç¤¾ãƒãƒƒãƒ] {result}")
                break  # æœ€åˆã®ãƒãƒƒãƒã§æ­¢ã‚ã‚‹

# ========== KINKAç¤¾ï¼ˆç›®çš„åœ°ãŒã€Œä¸Šæµ·ã€ã®å ´åˆã®ã¿ï¼‰ ==========
    if "ä¸Šæµ·" in keyword or "Shanghai" in keyword:
        logger.info(f"ğŸ” KINKAç¤¾ get_kinka_pdf_links.py ã«æ¸¡ã™ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: '{keyword}'")
        pdf_urls_kinka = await get_pdf_links_from_kinka(keyword)
        if not pdf_urls_kinka:
            logger.warning("âš ï¸ KINKAç¤¾ã®PDFãƒªãƒ³ã‚¯å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        else:
            for pdf_url in pdf_urls_kinka:
                result = await extract_schedule_positions(
                    url=pdf_url,
                    departure=departure,
                    destination=destination,
                    etd_date=etd_date,
                    eta_date=eta_date
                )
                if result:
                    result["company"] = "KINKA"
                    results.append(result)
                    logger.info(f"[KINKAç¤¾ãƒãƒƒãƒ] {result}")
                    break  # æœ€åˆã®ãƒãƒƒãƒã§æ­¢ã‚ã‚‹
    else:
        logger.info("ğŸ“› KINKAç¤¾ã¯ã€ä¸Šæµ·ã€ã®ã¨ãã®ã¿æ¤œç´¢å¯¾è±¡ã¨ãªã‚‹ãŸã‚ã€ä»Šå›ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸã€‚")

# ========== Shipmentlinkç¤¾ ========== 
    logger.info(f"ğŸ” Shipmentlinkç¤¾ get_pdf_links.py ã«æ¸¡ã™ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: '{keyword}'")
    pdf_urls_shipmentlink = await get_pdf_links_from_shipmentlink(departure, destination)
    
    if not pdf_urls_shipmentlink:
        logger.warning("âš ï¸ Shipmentlinkç¤¾ã®PDFãƒªãƒ³ã‚¯å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
    else:
        success = False
        for pdf_url in pdf_urls_shipmentlink:
            result = await extract_schedule_positions(
                url=pdf_url,
                departure=departure,
                destination=destination,
                etd_date=etd_date,
                eta_date=eta_date
            )
            if result:
                result["company"] = "Shipmentlink"
                results.append(result)
                logger.info(f"[Shipmentlinkç¤¾ãƒãƒƒãƒ] {result}")
                success = True
                break  # æœ€åˆã®ãƒãƒƒãƒã§æ­¢ã‚ã‚‹
        if not success:
            logger.warning("âš ï¸ Shipmentlinkç¤¾ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    # ========== Maerskç¤¾ ========== 
    maersk_result = await get_schedule_from_maersk(departure, destination, etd_date=req.etd_date)

    if maersk_result:
        for r in maersk_result:
            r["company"] = "Maersk"
            results.append(r)
        logger.info(f"[Maersk API æˆåŠŸ] {len(maersk_result)} ä»¶å–å¾—")

    # ========== Hapag-Lloydç¤¾ ========== 
    # try:
    #     hl_start_date = req.etd_date or req.eta_date
    #     logger.info(f"ğŸ” Hapag-Lloydç¤¾ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å–å¾—ã‚’å®Ÿè¡Œã—ã¾ã™: {departure} â†’ {destination} | {hl_start_date}")
    #     hl_results = await get_schedule_from_hapaglloyd(departure, destination, hl_start_date)
    #     if hl_results:
    #         results.extend(hl_results)
    #         logger.info(f"[Hapag-Lloydç¤¾ãƒãƒƒãƒ] {hl_results}")
    # except Exception as e:
    #     logger.warning(f"[Hapag-Lloydç¤¾å–å¾—å¤±æ•—] {e}")

    # ========== çµæœè¿”å´ ==========
    if results:
        logger.info(f"[âœ…MATCHED] {len(results)}ä»¶ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
        return results  # â† é…åˆ—ã¨ã—ã¦è¿”ã™
    else:
        logger.warning("âŒ å…¨ç¤¾ã®ã„ãšã‚Œã«ã‚‚ãƒãƒƒãƒã—ã¾ã›ã‚“ã§ã—ãŸ")
        return []  # â† ç©ºã®ãƒªã‚¹ãƒˆã§è¿”ã™ï¼ˆãƒ•ãƒ­ãƒ³ãƒˆã§ [] ã‚’æ‰±ãˆã‚‹ã‚ˆã†ã«ã™ã‚‹ï¼‰
    

@app.post("/update-feedback")
async def update_feedback(data: FeedbackRequest):
    logger.info(f"ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å—ä¿¡: URL={data.url}, ETD={data.etd}, ETA={data.eta}, Feedback={data.feedback}")
    try:
        with open("gpt_feedback_log.csv", "a", encoding="utf-8", newline='') as f:
            f.write(f'{data.url},{data.etd},{data.eta},{data.feedback}\n')
        return {"message": "ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’è¨˜éŒ²ã—ã¾ã—ãŸã€‚"}
    except Exception as e:
        logger.exception("ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯è¨˜éŒ²ä¸­ã«ã‚¨ãƒ©ãƒ¼")
        raise HTTPException(status_code=500, detail="ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

# -------------------------------
# ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢
# -------------------------------
@app.middleware("http")
async def catch_exceptions_middleware(request: Request, call_next):
    try:
        return await call_next(request)
    except Exception as e:
        # ã‚¨ãƒ©ãƒ¼ã®è©³ç´°ã‚’ãƒ­ã‚°ã«æ›¸ãï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ»è¡Œç•ªå·å«ã‚€ï¼‰
        error_trace = traceback.format_exc()
        logger.exception("æœªå‡¦ç†ã®ä¾‹å¤–ãŒç™ºç”Ÿã—ã¾ã—ãŸ:\n%s", error_trace)

        # Swaggerä¸Šã§è©³ç´°è¡¨ç¤º
        return JSONResponse(
            status_code=500,
            content={"detail": error_trace}  # â† ã‚¨ãƒ©ãƒ¼ã®è©³ç´°ãªã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹ä»˜ã
        )

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)